# Depth-Based Rotation Estimation

A perception engineering pipeline that processes **depth images** stored in a ROS2 SQLite bag (`depth.db3`), converts them into 3D point clouds, detects dominant planar surfaces using **RANSAC**, and estimates the **objectâ€™s rotation axis** across multiple frames.

---

## ğŸ§  Overview

This pipeline performs end-to-end depth data analysis using computer vision and geometry:

1. **Read Depth Frames** â€” Extract serialized ROS `sensor_msgs/Image` messages from a `.db3` bag file.
2. **Convert Depth to 3D Points** â€” Use camera intrinsics to compute `(X, Y, Z)` coordinates for each pixel.
3. **Plane Detection (RANSAC)** â€” Fit planes to noisy 3D data and isolate the dominant surface.
4. **Feature Computation** â€” Estimate visible area and angle between the plane normal and camera.
5. **Rotation Axis Estimation** â€” Aggregate normals across frames to find the objectâ€™s 3D rotation axis.
6. **Export Results** â€” Save per-frame data to `results.csv` and the final axis to `rotation_axis.txt`.

---

## ğŸ§© Pipeline Flow

```
Depth Image (.db3)
      â†“
Parse ROS Messages (BLOB â†’ NumPy array)
      â†“
Convert to Point Cloud (fx, fy, cx, cy)
      â†“
RANSAC Plane Detection
      â†“
Plane Area + Orientation Estimation
      â†“
Compute Mean Normal (Rotation Axis)
      â†“
Save Results (CSV + TXT)
```

ğŸ“Š _A visual diagram of this process can be found in:_  
[`assets/clean_depth_processing_flowchart.png`](./assets/clean_depth_processing_flowchart.png)

---

## ğŸ› ï¸ Features

- âœ… Parse ROS2 SQLite bag files (`.db3`)
- âœ… Convert depth maps â†’ 3D point clouds
- âœ… Fit planes robustly using **RANSAC**
- âœ… Compute surface normals, visible area, and rotation angles
- âœ… Estimate overall **rotation axis**
- âœ… Generate plots, GIFs, and animations (optional utilities)
- âœ… Outputs results in standard formats for downstream analysis

---

## ğŸ“‚ Project Structure

```
depth-based-rotation-estimation/
â”‚
â”œâ”€â”€ estimate_box_rotation.py          # Main pipeline script
â”œâ”€â”€ create_depth_animation_with_inliers.py  # Visualization and GIF creation
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ metadata.yaml                     # ROS2 metadata
â”œâ”€â”€ depth.db3                         # Example input data (ROS bag)
â”œâ”€â”€ results.csv                       # Per-frame analysis output
â”œâ”€â”€ rotation_axis.txt                 # Estimated rotation axis vector
â”œâ”€â”€ frames/                           # (Optional) Depth frame visualizations
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ clean_depth_processing_flowchart.png  # Pipeline flow diagram
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/sankalp-s/depth-based-rotation-estimation.git
cd depth-based-rotation-estimation
```

### 2ï¸âƒ£ Set Up Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### Basic Command
```bash
python estimate_box_rotation.py ./depth.db3 ./out_dir
```

### Arguments
| Argument | Description |
|-----------|--------------|
| `depth.db3` | Input ROS2 SQLite bag file containing depth messages |
| `out_dir` | Directory to save output files (`results.csv`, `rotation_axis.txt`) |

### Example Output
```
Done. Outputs saved to ./out_dir
```

---

## ğŸ“„ Output Files

| File | Description |
|------|--------------|
| `results.csv` | Per-frame results including plane normal, angle, and visible area |
| `rotation_axis.txt` | Final estimated rotation axis (unit vector) |
| `depth_animation_with_inliers.gif` | Optional visualization (if generated) |

**Example (results.csv):**
| frame | nx | ny | nz | angle_deg | visible_area_m2 |
|-------|----|----|----|------------|----------------|
| 1 | 0.03 | -0.87 | -0.49 | 120.5 | 5.14 |
| 2 | 0.02 | -0.45 | -0.89 | 115.7 | 5.08 |

---

## ğŸ§® Core Algorithms

### ğŸ”¹ Depth to Point Cloud
Converts each pixel `(i, j, z)` into a 3D coordinate `(X, Y, Z)` using the **pinhole camera model**:
\[
X = (j - c_x) \cdot Z / f_x, \quad
Y = (i - c_y) \cdot Z / f_y, \quad
Z = Z
\]

### ğŸ”¹ Plane Fitting (RANSAC)
Repeatedly samples 3 random points, computes the plane normal via cross product, and selects the plane with the **most inliers** (within a distance threshold).

### ğŸ”¹ Rotation Axis
The **mean of all detected plane normals**, normalized to a unit vector, represents the estimated **rotation axis** of the object.

---

## ğŸ–¼ï¸ Visualization (Optional)

To generate animations or GIFs of the depth frames:
```bash
python create_depth_animation_with_inliers.py ./depth.db3 ./out_dir
```

Outputs:
- `depth_animation_with_inliers.gif`
- `depth_animation_with_inliers.mp4`

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€” see the [LICENSE](./LICENSE) file for details.

---

## ğŸ‘¤ Author

**Sankalp Arora**  
Perception Engineer â€” 10xConstruction Apprentice Assignment  
ğŸ“§ sankalp.arora@example.com  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/sankalp-arora/)

---

## ğŸ’¡ Acknowledgements

- ROS2 bag format (`.db3`) handling inspired by `rosbag2_py` message serialization.  
- RANSAC implementation adapted from standard 3D geometry methods.  
- Visualization tools built using **Matplotlib** and **ImageIO**.

---

## ğŸ§  Future Enhancements
- Integrate real camera intrinsics via `camera_info` topic parsing.  
- Add interactive 3D visualization (e.g., Open3D, Plotly).  
- Extend to detect multiple planes and object pose changes over time.
